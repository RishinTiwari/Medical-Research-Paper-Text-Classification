{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfa58db0",
   "metadata": {},
   "source": [
    "### Rishin Tiwari\n",
    "# Text Classification Model Analysis\n",
    "\n",
    "In this Project, we aim to explore and compare different machine learning models for a text classification task. Our objective is to identify the most effective model based on performance metrics such as accuracy, precision, and recall. This notebook encompasses the entire workflow from data preprocessing, model training, hyperparameter tuning, to the final comparison and selection of the best model.\n",
    "\n",
    "### Problem statement, dataset, and objective of the analysis\n",
    "\n",
    "This assignment fosuses on text classification for cancer related documents. The selected dataset contains 7569 documents, which are distributed across 3 cancer types: thyroid, colon and lung. The purposed of the analysis is to conduct text analysis and build machine learning models to accurately identify the type of cancer on each observation. \n",
    "\n",
    "The dataset can be downloaded from the following source: https://www.kaggle.com/datasets/falgunipatel19/biomedical-text-publication-classification/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f6aa81",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "\n",
    "### Data Preprocessing Steps:\n",
    "\n",
    "- **Loading and Understanding the Data**:performing exploratory data analysis to understand the structure, content, and any immediate data quality issues.\n",
    "- **Cleaning Data**: Removing special characters, numbers, and unnecessary whitespace.\n",
    "- **Tokenization**: Splitting text into individual words or tokens.\n",
    "- **Lemmatization/Stemming**: Reducing words to their base or root form.\n",
    "- **Stop Word Removal**: Eliminating common words that provide little value in the analysis.\n",
    "- **Vectorization (TF-IDF)**: Converting text into numeric form to create feature vectors.\n",
    "- **Feature Engineering**:  Encode the text data using sklearn's TfidfVectorizer to convert text data into a matrix of TF-IDF features.\n",
    "- **Splitting the Data**: The data is divided into training and testing sets to evaluate the model's performance on unseen data. \n",
    "\n",
    "### Rationale Behind Chosen Methods:\n",
    "\n",
    "- **Cleaning Data**: Ensures data quality and consistency, which are fundamental for reliable model predictions.\n",
    "- **Feature Engineering**: Leverages domain knowledge to introduce new relevant features, potentially improving model performance by providing more informative signals.\n",
    "- **Text Processing**: Text data must be converted into a numerical format for machine learning algorithms to process it. This step is crucial for any task involving text analysis.\n",
    "- **Normalization/Standardization**: Helps to equalize the influence of features on the model's outcome, improving training stability and performance.\n",
    "- **Splitting the Data**: Essential for validating the model's ability to generalize from the training data to unseen data, providing an estimate of its performance in real-world scenarios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing #for preprocessing text data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #TfidfVectorizer (which includes pre-processing, tokenization, and filtering out stop words)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from string import punctuation\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0c215-d17d-4ff3-95d8-f10807837b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Cancer_Dataset.csv\", encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the irrelevant column\n",
    "df = df.drop('Unnamed: 0',axis=1)\n",
    "# Renaming the column names\n",
    "df.columns=['Class_Labels', 'Research_Paper_Text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79b978c-ab06-4deb-9158-4071ce06947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Null Values\n",
    "count = df['Class_Labels'].isna().sum()\n",
    "if  count > 0:\n",
    "    print(f'Found {count} null values in Class_Labels column')\n",
    "    #df['Class_Labels'].fillna('missing', inplace=True) # though we could do this, we will drop the rows instead - as there is no way to impute the text\n",
    "    df = df.dropna(subset=['Class_Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afbf713-97ec-4d21-98d3-28d5334941fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Null Values\n",
    "count = df['Research_Paper_Text'].isna().sum()\n",
    "if  count > 0:\n",
    "    print(f'Found {count} null values in Research_Paper_Text column')\n",
    "    #df['Research_Paper_Text'].fillna('missing', inplace=True) # though we could do this, we will drop the rows instead - as there is no way to impute the text\n",
    "    df = df.dropna(subset=['Research_Paper_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3352787f-5820-48d1-b071-32072ad796f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class_Labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f4fba-dfab-4d14-a23f-afda79653bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking data imbalance\n",
    "df['Class_Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e5abe-37dd-4117-a0c0-c5c6d268b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords list\n",
    "stopwords_list = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define function for text cleaning and lemmatization\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Cleaning and lemmatization\n",
    "    clean_lemmatized_text = [lemmatizer.lemmatize(token.lower()) for token in tokens if (token.lower() not in punctuation) and (token.lower() not in stopwords_list) and (len(token) > 2) and token.isalpha()]\n",
    "    return \" \".join(clean_lemmatized_text)\n",
    "\n",
    "# Apply text preprocessing to the 'Research_Paper_Text' column\n",
    "df['Research_Paper_Text'] = df['Research_Paper_Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf007f7-ca07-4fa9-bc8e-8f41609bcc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db9ca3-6b0d-484e-b1f6-13417346d18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Research_Paper_Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76cb8e-ab8b-43f0-bc63-d0abfa790f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Class_Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d33994-082c-4264-b904-e5dac3aba81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "classes = list(enumerate(le.classes_))\n",
    "print(classes)\n",
    "y = le.transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c274d-9046-4b82-862f-46ded2bb60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aee252-3f7d-463a-a368-07e2aa2e3975",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580f345-49a8-491f-836f-d4ea1b3aabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49ae110-90d4-4c24-8394-a90fbef370ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80047503-a29b-40da-9890-1dd8c1bbd3ab",
   "metadata": {},
   "source": [
    "Sklearn: Text preparation\n",
    "For simplicity (and focus), we will not do any text cleaning or preprocessing. We will just use the raw text as input to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07ede2-452e-4d70-a3df-95ee125ef901",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer() \n",
    "\n",
    "X_train = tfidf_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1cf727-8651-4a91-82ba-1a6e2608db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91313a30-9083-4855-ba4d-65c8c234b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ad013-4694-45be-8343-569d2fe127c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e337210-7262-4842-a95b-332a7c72d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the TfidfVectorizer transformation\n",
    "\n",
    "\n",
    "X_test = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f932b-9b8e-47e0-ba6e-2a3fab997ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50dabd-1666-49b1-aec4-907de1aa4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These data sets are \"sparse matrix\". We can't see them unless we convert using toarray()\n",
    "np.set_printoptions(precision=3)\n",
    "print(X_train.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17697994-56f0-41f7-8f10-2ab28332ad72",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis (Singular Value Decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbfd93e-4b20-4760-b07e-0fe88966f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=1000, n_iter=10) #n_components is the number of topics, which should be less than the number of features, and number of rows in the matrix\n",
    "\n",
    "X_train_dim_reduct = svd.fit_transform(X_train)\n",
    "X_test__dim_reduct = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24586354-d8db-4f0b-9ee5-ce3d46b43275",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d748f1-77bb-42b6-895a-5a6f28578566",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dim_reduct.shape, X_test__dim_reduct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4842fb08-d920-47bb-978b-67b4118cfcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dim_reduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f88f79-ffc3-47dc-a8db-2b952cb2942d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_train_dim_reduct, columns=[f\"svd{num:04}\" for num in range(0,X_train_dim_reduct.shape[1])])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf141c",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "We train and evaluate seven different models to understand their baseline performance on our dataset. Each model is assessed based on its accuracy on the training and test sets. The models include:\n",
    "\n",
    "1. Logistic Regression\n",
    "2. K-Nearest Neighbors (KNN)\n",
    "3. Support Vector Machine (SVM)\n",
    "4. Decision Tree\n",
    "5. Random Forest\n",
    "6. AdaBoost\n",
    "7. XGBoost\n",
    "\n",
    "For each model, the training process is followed by an evaluation using accuracy as the primary metric.\n",
    "\n",
    "## Hyperparameter Tuning\n",
    "\n",
    "To optimize the performance of each model, we apply hyperparameter tuning using GridSearchCV.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0955fc8",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d3648-5995-4ce0-bac8-fbbe6e254d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "lr_clf.fit(X_train_dim_reduct, y_train)\n",
    "\n",
    "y_train_pred_lr = lr_clf.predict(X_train_dim_reduct)\n",
    "y_test_pred_lr = lr_clf.predict(X_test__dim_reduct)\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred_lr):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred_lr):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f864918e",
   "metadata": {},
   "source": [
    "Hyper parameter tuning for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4430dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "start_time = time.time()\n",
    "lr_grid = GridSearchCV(LogisticRegression(random_state=42, max_iter=1000), \n",
    "                       {'C': [0.1, 1, 10], 'solver': ['liblinear']}, \n",
    "                       cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "lr_grid.fit(X_train_dim_reduct, y_train)\n",
    "\n",
    "print(f\"Best LR Parameters: {lr_grid.best_params_}\")\n",
    "print(f\"Best LR Score: {lr_grid.best_score_:.4f}\")\n",
    "\n",
    "print(\"Logistic Regression Comparison:\")\n",
    "print(f\"Baseline Train Accuracy: {accuracy_score(y_train, y_train_pred_lr):.4f}, Test Accuracy: {accuracy_score(y_test, y_test_pred_lr):.4f}\")\n",
    "print(f\"After Tuning Train Accuracy: {lr_grid.best_score_:.4f}, Test Accuracy: {accuracy_score(y_test, lr_grid.best_estimator_.predict(X_test__dim_reduct)):.4f}\")\n",
    "\n",
    "\n",
    "lr_time = time.time() - start_time\n",
    "\n",
    "print(f\"Logistic Regression Tuning Time: {lr_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dabe17f",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d32ea-9650-4c2c-8554-2f22793b6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train_dim_reduct, y_train)\n",
    "\n",
    "y_train_pred_knn = knn_clf.predict(X_train_dim_reduct)\n",
    "y_test_pred_knn = knn_clf.predict(X_test__dim_reduct)\n",
    "\n",
    "print(\"K-Nearest Neighbors (KNN):\")\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred_knn):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred_knn):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb12f738",
   "metadata": {},
   "source": [
    "Hyper parameter tuning for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd9216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "start_time = time.time()\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), \n",
    "                        {'n_neighbors': [3, 5, 7], 'metric': ['euclidean', 'manhattan']}, \n",
    "                        cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "knn_grid.fit(X_train_dim_reduct, y_train)\n",
    "\n",
    "print(f\"Best KNN Parameters: {knn_grid.best_params_}\")\n",
    "print(f\"Best KNN Score: {knn_grid.best_score_:.4f}\")\n",
    "\n",
    "print(\"KNN Comparison:\")\n",
    "print(f\"Baseline Train Accuracy: {accuracy_score(y_train, y_train_pred_knn):.4f}, Test Accuracy: {accuracy_score(y_test, y_test_pred_knn):.4f}\")\n",
    "print(f\"After Tuning Train Accuracy: {knn_grid.best_score_:.4f}, Test Accuracy: {accuracy_score(y_test, knn_grid.best_estimator_.predict(X_test__dim_reduct)):.4f}\")\n",
    "knn_time = time.time() - start_time\n",
    "\n",
    "print(f\"KNN Tuning Time: {knn_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063e010b",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e38007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_train_dim_reduct, y_train)\n",
    "\n",
    "y_train_pred_svm = svm_clf.predict(X_train_dim_reduct)\n",
    "y_test_pred_svm = svm_clf.predict(X_test__dim_reduct)\n",
    "\n",
    "print(\"Support Vector Machine (SVM):\")\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred_svm):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred_svm):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c8aa5d",
   "metadata": {},
   "source": [
    "Hyper parameter tuning for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae2efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "svm_grid = GridSearchCV(SVC(random_state=42), \n",
    "                        {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}, \n",
    "                        cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "svm_grid.fit(X_train_dim_reduct, y_train)\n",
    "print(f\"Best SVM Parameters: {svm_grid.best_params_}\")\n",
    "print(f\"Best SVM Score: {svm_grid.best_score_:.4f}\")\n",
    "\n",
    "print(\"SVM Comparison:\")\n",
    "print(f\"Baseline Train Accuracy: {accuracy_score(y_train, y_train_pred_svm):.4f}, Test Accuracy: {accuracy_score(y_test, y_test_pred_svm):.4f}\")\n",
    "print(f\"After Tuning Train Accuracy: {svm_grid.best_score_:.4f}, Test Accuracy: {accuracy_score(y_test, svm_grid.best_estimator_.predict(X_test__dim_reduct)):.4f}\")\n",
    "svm_time = time.time() - start_time\n",
    "\n",
    "print(f\"SVM Tuning Time: {svm_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fdd32c",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92602358",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train_dim_reduct, y_train)\n",
    "\n",
    "y_train_pred_dt = dt_clf.predict(X_train_dim_reduct)\n",
    "y_test_pred_dt = dt_clf.predict(X_test__dim_reduct)\n",
    "\n",
    "print(\"Decision Tree:\")\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred_dt):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred_dt):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e211f408",
   "metadata": {},
   "source": [
    "Hyper parameter tuning for decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ae10b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "dt_param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt_grid = GridSearchCV(dt, dt_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "dt_grid.fit(X_train_dim_reduct, y_train)\n",
    "\n",
    "print(f\"Best parameters for Decision Tree: {dt_grid.best_params_}\")\n",
    "print(f\"Best score for Decision Tree: {dt_grid.best_score_}\")\n",
    "\n",
    "print(\"Decision Tree Comparison:\")\n",
    "print(f\"Baseline Train Accuracy: {accuracy_score(y_train, y_train_pred_dt):.4f}, Test Accuracy: {accuracy_score(y_test, y_test_pred_dt):.4f}\")\n",
    "print(f\"After Tuning Train Accuracy: {dt_grid.best_score_:.4f}, Test Accuracy: {accuracy_score(y_test, dt_grid.best_estimator_.predict(X_test__dim_reduct)):.4f}\")\n",
    "dt_time = time.time() - start_time\n",
    "\n",
    "print(f\"Decision Tree Tuning Time: {dt_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc1e08",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_leaf_nodes=10, n_jobs=-1)\n",
    "rf_clf.fit(X_train_dim_reduct, y_train)\n",
    "\n",
    "y_train_pred_rf = rf_clf.predict(X_train_dim_reduct)\n",
    "y_test_pred_rf = rf_clf.predict(X_test__dim_reduct)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred_rf):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred_rf):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021477ea",
   "metadata": {},
   "source": [
    "Hyper parameter tuning for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19e043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "rf_grid.fit(X_train_dim_reduct, y_train)\n",
    "\n",
    "print(f\"Best parameters for Random Forest: {rf_grid.best_params_}\")\n",
    "print(f\"Best score for Random Forest: {rf_grid.best_score_}\")\n",
    "\n",
    "print(\"Random Forest Comparison:\")\n",
    "print(f\"Baseline Train Accuracy: {accuracy_score(y_train, y_train_pred_rf):.4f}, Test Accuracy: {accuracy_score(y_test, y_test_pred_rf):.4f}\")\n",
    "print(f\"After Tuning Train Accuracy: {rf_grid.best_score_:.4f}, Test Accuracy: {accuracy_score(y_test, rf_grid.best_estimator_.predict(X_test__dim_reduct)):.4f}\")\n",
    "rf_time = time.time() - start_time\n",
    "\n",
    "print(f\"Random Forest Tuning Time: {rf_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926c5b46",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f23eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ada_clf = AdaBoostClassifier()\n",
    "ada_clf.fit(X_train_dim_reduct, y_train)\n",
    "\n",
    "y_train_pred_ada = ada_clf.predict(X_train_dim_reduct)\n",
    "y_test_pred_ada = ada_clf.predict(X_test__dim_reduct)\n",
    "\n",
    "print(\"AdaBoost:\")\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred_ada):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred_ada):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a172dfbf",
   "metadata": {},
   "source": [
    "Hyper parameter tuning for AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4c411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "ab_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "ab = AdaBoostClassifier(random_state=42)\n",
    "ab_grid = GridSearchCV(ab, ab_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "ab_grid.fit(X_train_dim_reduct, y_train)\n",
    "\n",
    "print(f\"Best parameters for AdaBoost: {ab_grid.best_params_}\")\n",
    "print(f\"Best score for AdaBoost: {ab_grid.best_score_}\")\n",
    "\n",
    "print(\"AdaBoost Comparison:\")\n",
    "print(f\"Baseline Train Accuracy: {accuracy_score(y_train, y_train_pred_ada):.4f}, Test Accuracy: {accuracy_score(y_test, y_test_pred_ada):.4f}\")\n",
    "print(f\"After Tuning Train Accuracy: {ab_grid.best_score_:.4f}, Test Accuracy: {accuracy_score(y_test, ab_grid.best_estimator_.predict(X_test__dim_reduct)):.4f}\")\n",
    "ab_time = time.time() - start_time\n",
    "\n",
    "print(f\"AdaBoost Tuning Time: {ab_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224250c0",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ab6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf.fit(X_train_dim_reduct, y_train)\n",
    "\n",
    "y_train_pred_xgb = xgb_clf.predict(X_train_dim_reduct)\n",
    "y_test_pred_xgb = xgb_clf.predict(X_test__dim_reduct)\n",
    "\n",
    "print(\"XGBoost:\")\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred_xgb):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred_xgb):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b83c40",
   "metadata": {},
   "source": [
    "Hyper parameter tuning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d128623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), \n",
    "                        {'learning_rate': [0.1, 0.2], 'max_depth': [3, 6], 'n_estimators': [50, 100]}, \n",
    "                        cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "xgb_grid.fit(X_train_dim_reduct, y_train)\n",
    "print(f\"Best XGB Parameters: {xgb_grid.best_params_}\")\n",
    "print(f\"Best XGB Score: {xgb_grid.best_score_:.4f}\")\n",
    "\n",
    "print(\"XGBoost Comparison:\")\n",
    "print(f\"Baseline Train Accuracy: {accuracy_score(y_train, y_train_pred_xgb):.4f}, Test Accuracy: {accuracy_score(y_test, y_test_pred_xgb):.4f}\")\n",
    "print(f\"After Tuning Train Accuracy: {xgb_grid.best_score_:.4f}, Test Accuracy: {accuracy_score(y_test, xgb_grid.best_estimator_.predict(X_test__dim_reduct)):.4f}\")\n",
    "\n",
    "xgb_time = time.time() - start_time\n",
    "\n",
    "print(f\"XGBoost Tuning Time: {xgb_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb9131",
   "metadata": {},
   "source": [
    "# Challenges Faced\n",
    "\n",
    "Applying the model and performing hyper parameter tuning was complex as this was a very large dataset. The implementation of hyper parameter tuning had a very high computational cost, as shown in the results, with models taking up to 184 seconds to run. This made it very difficult to test ad make adjustments to the models and code, as it will take significant time. \n",
    "\n",
    "Another challenge might be fighting overfitting, as many of the models present very high accuracies, which might suggest that the data be biased or that the model is trying to explain too much from the training sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a839f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "baseline_accuracies = {\n",
    "    'Logistic Regression': accuracy_score(y_test, y_test_pred_lr),\n",
    "    'KNN': accuracy_score(y_test, y_test_pred_knn),\n",
    "    'SVM': accuracy_score(y_test, y_test_pred_svm),\n",
    "    'Decision Tree': accuracy_score(y_test, y_test_pred_dt),\n",
    "    'Random Forest': accuracy_score(y_test, y_test_pred_rf),\n",
    "    'AdaBoost': accuracy_score(y_test, y_test_pred_ada),\n",
    "    'XGBoost': accuracy_score(y_test, y_test_pred_xgb)\n",
    "}\n",
    "\n",
    "tuned_accuracies = {\n",
    "    'Logistic Regression': accuracy_score(y_test, lr_grid.best_estimator_.predict(X_test__dim_reduct)),\n",
    "    'KNN': accuracy_score(y_test, knn_grid.best_estimator_.predict(X_test__dim_reduct)),\n",
    "    'SVM': accuracy_score(y_test, svm_grid.best_estimator_.predict(X_test__dim_reduct)),\n",
    "    'Decision Tree': accuracy_score(y_test, dt_grid.best_estimator_.predict(X_test__dim_reduct)),\n",
    "    'Random Forest': accuracy_score(y_test, rf_grid.best_estimator_.predict(X_test__dim_reduct)),\n",
    "    'AdaBoost': accuracy_score(y_test, ab_grid.best_estimator_.predict(X_test__dim_reduct)),\n",
    "    'XGBoost': accuracy_score(y_test, xgb_grid.best_estimator_.predict(X_test__dim_reduct))\n",
    "}\n",
    "\n",
    "tuned_times = {\n",
    "    'Logistic Regression': lr_time,\n",
    "    'KNN': knn_time,\n",
    "    'SVM': svm_time,\n",
    "    'Decision Tree': dt_time,\n",
    "    'Random Forest': rf_time,\n",
    "    'AdaBoost': ab_time,\n",
    "    'XGBoost': xgb_time\n",
    "}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d537b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Logistic Regression\", \"KNN\", \"SVM\", \"Decision Tree\", \"Random Forest\", \"AdaBoost\", \"XGBoost\"]\n",
    "print(f\"{'Model':<20} {'Baseline Acc.':<15} {'Tuned Acc.':<15} {'Tuning Time (s)':<15}\")\n",
    "for model in models:\n",
    "    print(f\"{model:<20} {baseline_accuracies[model]:<15.4f} {tuned_accuracies[model]:<15.4f} {tuned_times[model]:<15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589a013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print comparison of baseline vs tuned accuracies\n",
    "for model in baseline_accuracies.keys():\n",
    "    print(f\"{model}: Baseline Accuracy = {baseline_accuracies[model]:.4f}.\")\n",
    "\n",
    "# Identify the best performing model after tuning\n",
    "best_model = max(tuned_accuracies, key=tuned_accuracies.get)\n",
    "print(f\"\\nThe best performing model after hyperparameter tuning is {best_model} with an accuracy of {tuned_accuracies[best_model]:.4f}, Tuned Accuracy = {tuned_accuracies[model]:.4f}, Tuned time = {tuned_times[best_model]:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5920a727",
   "metadata": {},
   "source": [
    "## Model Performance Improvements\n",
    "\n",
    "The results reveal significant improvements in accuracy for some models post-tuning, notably for **Logistic Regression** and **SVM**, where accuracy increased from 0.9348 to 0.9498 and from 0.9256 to 0.9599, respectively. These improvements underscore the value of hyperparameter tuning in optimizing model performance, particularly for models that are sensitive to parameter settings.\n",
    "\n",
    "**Random Forest** and **AdaBoost** exhibited the most remarkable performance shifts. Random Forest's accuracy leaped from 0.8159 to 0.9982, while AdaBoost saw a modest increase from 0.6684 to 0.7107. This dramatic improvement for Random Forest suggests that the default parameters were far from optimal and that the model significantly benefited from tuning. For AdaBoost, the gain, although smaller, indicates a positive direction towards optimizing its performance.\n",
    "\n",
    "Conversely, **KNN**, **Decision Tree**, and **XGBoost** maintained the same high level of accuracy before and after tuning, which suggests two possibilities: either the default parameters were already near-optimal, or the range of hyperparameters explored during tuning did not significantly impact these models' performance.\n",
    "\n",
    "## Computational Costs\n",
    "\n",
    "The computational cost associated with tuning varied widely among the models. Notably, **AdaBoost** and **Random Forest** required the most time, with 184.71 and 152.09 seconds, respectively. This significant computational investment yielded substantial accuracy improvements for Random Forest, making the cost worthwhile in this scenario. However, for AdaBoost, the considerable tuning time did not result in a similarly dramatic performance increase, highlighting a less efficient use of computational resources.\n",
    "\n",
    "**SVM** also showed a notable computational cost at 44.52 seconds but delivered a solid performance improvement, indicating a good balance between cost and benefit.\n",
    "\n",
    "In contrast, **Logistic Regression**, despite its relatively low computational cost of 4.20 seconds, achieved a meaningful accuracy improvement, showcasing an efficient tuning process.\n",
    "\n",
    "## Best Model Selection\n",
    "\n",
    "Considering both the accuracy improvements and the computational costs, **Random Forest** stands out as the most improved model due to tuning, achieving the highest accuracy among all models post-tuning. This remarkable improvement demonstrates the model's potential when optimally tuned, despite the higher computational cost.\n",
    "\n",
    "However, if computational efficiency is a priority, **Logistic Regression** offers a compelling alternative, with a significant accuracy improvement and minimal tuning time.\n",
    "\n",
    "## Future Directions\n",
    "\n",
    "The results suggest several avenues for further exploration:\n",
    "\n",
    "- **Exploring Further Hyperparameter Ranges**: For models like KNN, Decision Tree, and XGBoost, which showed no improvement with tuning, exploring a broader or different set of hyperparameters might uncover untapped performance potential.\n",
    "- **Feature Engineering and Selection**: Improving model performance might also be achieved by refining the input features, suggesting a direction for further research and experimentation.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a93b04",
   "metadata": {},
   "source": [
    "# Discussion and Conclusion\n",
    "\n",
    "\n",
    "### Insights Gained and Potential Applications:\n",
    "-The high accuracy achieved by KNN suggests that the dataset contains clear, distinguishable patterns that KNN can exploit effectively, making it highly suitable for applications requiring high precision and reliability.\n",
    "-The insights gained from the model comparison and selection process can inform future projects, emphasizing the value of exploratory data analysis, feature engineering, and rigorous model evaluation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
